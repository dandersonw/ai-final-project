{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "MY_SRC = '../src/'\n",
    "if MY_SRC not in sys.path:\n",
    "    sys.path.append(MY_SRC)\n",
    "\n",
    "import text_model\n",
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Derick/anaconda3/envs/tf-1.12/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/10 [==>...........................] - ETA: 35s - loss: 5.8583 - acc: 0.0909"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need touse the repeat() function when building your dataset.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fef016fac50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(text_model)\n",
    "importlib.reload(data)\n",
    "\n",
    "config = text_model.Config(lstm_layers=1,\n",
    "                           lstm_size=128,\n",
    "                           embedding_size=128,\n",
    "                           attention_num_heads=3,\n",
    "                           attention_head_size=64,\n",
    "                           feature_params={'vocab_size': 255},)\n",
    "model = text_model.create_model(config)\n",
    "\n",
    "dataset = data.make_dataset('/mnt/c/Users/Derick/Downloads/testing_data.tfrecord')\n",
    "\n",
    "model.fit(dataset, steps_per_epoch=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-1.12]",
   "name": "conda-env-tf-1.12-py"
  },
  "name": "train_text_model.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
