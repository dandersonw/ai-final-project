* First good run of self-attention model

commit: 8deb5c5c8d7e328b106e44af7c8cdc5680cbd5f4

=first-good-attention=


loss: 0.3746 - acc: 0.8555 - val_loss: 0.8007 - val_acc: 0.7507

=first-good-simple=

Pending...

#+begin_src python
config = text_model.Config(lstm_layers=1,
                           lstm_size=256,
                           embedding_size=64,
                           attention_num_heads=3,
                           attention_head_size=64,
                           # embedding_regularization_coef=1e-4,
                           # dense_regularization_coef=1e-4,
                           feature_params={'vocab_size': 255},)
#+end_src
